{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d9f29fe",
   "metadata": {},
   "source": [
    "# Bring in modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "668fe98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version 2.7.0\n",
      "sklearn version 1.0.1\n",
      "numpy version 1.20.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"tensorflow version\", tf.__version__)\n",
    "\n",
    "import sklearn\n",
    "print(\"sklearn version\", sklearn.__version__)\n",
    "\n",
    "import numpy as np\n",
    "print(\"numpy version\", np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bede89a",
   "metadata": {},
   "source": [
    "# Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6bdee7c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# With numpy, when a value is printed display more values per line\n",
    "# https://stackoverflow.com/questions/21971449/how-do-i-increase-the-cell-width-of-the-jupyter-ipython-notebook-in-my-browser\n",
    "np.set_printoptions(linewidth=5000)\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# In Pandas, display more rows and columns\n",
    "# https://stackoverflow.com/a/11711637/4375369\n",
    "# pd.set_option('display.max_rows', 100)\n",
    "# pd.set_option('display.max_columns', 100)\n",
    "\n",
    "RANDOM_SEED_FOR_REPRODUCIBILITY = 777"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb27cdd",
   "metadata": {},
   "source": [
    "# Get raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c19aeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_raw, y_train_raw), (X_test_raw, y_test_raw) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# X_train_raw, y_train_raw, X_test_raw, y_test_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142202ba",
   "metadata": {},
   "source": [
    "# Shuffle raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "adf551c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.utils.shuffle.html\n",
    "\n",
    "X_train_raw, y_train_raw = sklearn.utils.shuffle(X_train_raw, y_train_raw, random_state=RANDOM_SEED_FOR_REPRODUCIBILITY)\n",
    "\n",
    "X_test_raw, y_test_raw = sklearn.utils.shuffle(X_test_raw, y_test_raw, random_state=RANDOM_SEED_FOR_REPRODUCIBILITY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e9cb12",
   "metadata": {},
   "source": [
    "# Normalize example data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4dea6e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/api_docs/python/tf/math/reduce_max\n",
    "\n",
    "maximum_value = tf.math.reduce_max(X_train_raw)\n",
    "\n",
    "assert maximum_value == 255, \"Maximum value is expected to be 255 but got {}\".format(maximum_value)\n",
    "\n",
    "X_train_normalized = X_train_raw / maximum_value\n",
    "\n",
    "X_test_normalized = X_test_raw / maximum_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628796e8",
   "metadata": {},
   "source": [
    "# One-hot encode label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2290cf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical\n",
    "\n",
    "y_train_one_hot_encoded = tf.keras.utils.to_categorical(y_train_raw)\n",
    "\n",
    "y_test_one_hot_encoded = tf.keras.utils.to_categorical(y_test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfa2f77",
   "metadata": {},
   "source": [
    "# Compare Raw to Modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5fcccc00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  80, 167, 167, 249, 175, 167, 136,  62,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   8, 137, 222, 254, 254, 254, 254, 254, 254, 254, 139,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 129, 254, 254, 211, 106,  81,  53, 245, 254, 254, 119,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 202, 254, 148,   8,   0,   0, 140, 254, 254, 126,   6,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  31, 247, 251,  58,   0,   0,   0, 195, 254, 170,   6,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  36, 254, 251,  58,   0,   0, 102, 251, 254,  80,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  20, 230, 254,  70,   0,   9, 198, 254, 133,   8,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 165, 254, 142,   0, 152, 254, 222,  15,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  50, 252, 251, 154, 254, 251,  71,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 193, 254, 254, 254, 153,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 133, 255, 254, 176,   3,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  17, 231, 254, 254,  88,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   9, 172, 254, 254, 254, 170,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  10, 202, 254, 226,  56, 237, 247,   8,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0, 135, 254, 225,  42,   0, 175, 254,   8,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  99, 248, 224,  42,   0,   0, 175, 254,   8,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0, 228, 254,  92,   0,   0,   0, 175, 254,   8,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0, 222, 254,  44,   0,   0,   7, 181, 188,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0, 106, 252, 184,  97, 103, 211, 251,  85,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  83, 239, 254, 254, 220,  79,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], dtype=uint8),\n",
       " <tf.Tensor: shape=(28, 28), dtype=float32, numpy=\n",
       " array([[0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.01176471, 0.3137255 , 0.654902  , 0.654902  , 0.9764706 , 0.6862745 , 0.654902  , 0.53333336, 0.24313726, 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.03137255, 0.5372549 , 0.87058824, 0.99607843, 0.99607843, 0.99607843, 0.99607843, 0.99607843, 0.99607843, 0.99607843, 0.54509807, 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.5058824 , 0.99607843, 0.99607843, 0.827451  , 0.41568628, 0.31764707, 0.20784314, 0.9607843 , 0.99607843, 0.99607843, 0.46666667, 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.7921569 , 0.99607843, 0.5803922 , 0.03137255, 0.        , 0.        , 0.54901963, 0.99607843, 0.99607843, 0.49411765, 0.02352941, 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.12156863, 0.96862745, 0.9843137 , 0.22745098, 0.        , 0.        , 0.        , 0.7647059 , 0.99607843, 0.6666667 , 0.02352941, 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.14117648, 0.99607843, 0.9843137 , 0.22745098, 0.        , 0.        , 0.4       , 0.9843137 , 0.99607843, 0.3137255 , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.07843138, 0.9019608 , 0.99607843, 0.27450982, 0.        , 0.03529412, 0.7764706 , 0.99607843, 0.52156866, 0.03137255, 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.64705884, 0.99607843, 0.5568628 , 0.        , 0.59607846, 0.99607843, 0.87058824, 0.05882353, 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.19607843, 0.9882353 , 0.9843137 , 0.6039216 , 0.99607843, 0.9843137 , 0.2784314 , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.75686276, 0.99607843, 0.99607843, 0.99607843, 0.6       , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.52156866, 1.        , 0.99607843, 0.6901961 , 0.01176471, 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.06666667, 0.90588236, 0.99607843, 0.99607843, 0.34509805, 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.03529412, 0.6745098 , 0.99607843, 0.99607843, 0.99607843, 0.6666667 , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.03921569, 0.7921569 , 0.99607843, 0.8862745 , 0.21960784, 0.92941177, 0.96862745, 0.03137255, 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.5294118 , 0.99607843, 0.88235295, 0.16470589, 0.        , 0.6862745 , 0.99607843, 0.03137255, 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.3882353 , 0.972549  , 0.8784314 , 0.16470589, 0.        , 0.        , 0.6862745 , 0.99607843, 0.03137255, 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.89411765, 0.99607843, 0.36078432, 0.        , 0.        , 0.        , 0.6862745 , 0.99607843, 0.03137255, 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.87058824, 0.99607843, 0.17254902, 0.        , 0.        , 0.02745098, 0.70980394, 0.7372549 , 0.00784314, 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.41568628, 0.9882353 , 0.72156864, 0.38039216, 0.40392157, 0.827451  , 0.9843137 , 0.33333334, 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.3254902 , 0.9372549 , 0.99607843, 0.99607843, 0.8627451 , 0.30980393, 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ]], dtype=float32)>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_raw[0], X_train_normalized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f8c2468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   2,   7,  50, 238, 155,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 142, 254, 254, 254, 154,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  48, 231, 254, 254, 177, 152,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  50, 229, 254, 247, 187,  15,  52,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   7, 195, 254, 254, 158,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 135, 254, 254, 188,  18,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   9, 193, 254, 243,  46,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   9,  91, 254, 254, 161,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   9, 151, 254, 254, 224,  32,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  10, 191, 254, 254, 239,  47,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  63, 234, 254, 254, 209,  69,  69,  69,  69,  69,  42,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0, 162, 254, 254, 254, 254, 254, 254, 254, 254, 254, 233,  87,   6,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0, 162, 254, 254, 254, 254, 254, 231, 199, 254, 254, 254, 254,  94,   4,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  11, 194, 254, 254, 192, 136,  43,  30,  14,  43, 104, 187, 254, 254,  12,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   5, 175, 254, 254,  74,   0,   0,   0,   0,   0,   0, 100, 254, 254,  12,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0, 162, 254, 254,  74,   0,   0,   0,   0,   0,  37, 222, 254, 210,   7,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0, 162, 254, 254,  74,   0,   0,   0,  34, 107, 222, 254, 255,  30,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   6,  50,   0,   0, 162, 254, 254, 242, 237, 237, 237, 243, 254, 254, 254, 208,  10,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   7,  60,   0,   0,  26, 214, 254, 254, 254, 254, 254, 254, 254, 153,  88,   7,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  25, 154, 254, 254, 221, 130, 130,  88,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], dtype=uint8),\n",
       " <tf.Tensor: shape=(28, 28), dtype=float32, numpy=\n",
       " array([[0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.00784314, 0.02745098, 0.19607843, 0.93333334, 0.60784316, 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.5568628 , 0.99607843, 0.99607843, 0.99607843, 0.6039216 , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.1882353 , 0.90588236, 0.99607843, 0.99607843, 0.69411767, 0.59607846, 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.19607843, 0.8980392 , 0.99607843, 0.96862745, 0.73333335, 0.05882353, 0.20392157, 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.02745098, 0.7647059 , 0.99607843, 0.99607843, 0.61960787, 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.5294118 , 0.99607843, 0.99607843, 0.7372549 , 0.07058824, 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.03529412, 0.75686276, 0.99607843, 0.9529412 , 0.18039216, 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.03529412, 0.35686275, 0.99607843, 0.99607843, 0.6313726 , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.03529412, 0.5921569 , 0.99607843, 0.99607843, 0.8784314 , 0.1254902 , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.03921569, 0.7490196 , 0.99607843, 0.99607843, 0.9372549 , 0.18431373, 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.24705882, 0.91764706, 0.99607843, 0.99607843, 0.81960785, 0.27058825, 0.27058825, 0.27058825, 0.27058825, 0.27058825, 0.16470589, 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.63529414, 0.99607843, 0.99607843, 0.99607843, 0.99607843, 0.99607843, 0.99607843, 0.99607843, 0.99607843, 0.99607843, 0.9137255 , 0.34117648, 0.02352941, 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.63529414, 0.99607843, 0.99607843, 0.99607843, 0.99607843, 0.99607843, 0.90588236, 0.78039217, 0.99607843, 0.99607843, 0.99607843, 0.99607843, 0.36862746, 0.01568628, 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.04313726, 0.7607843 , 0.99607843, 0.99607843, 0.7529412 , 0.53333336, 0.16862746, 0.11764706, 0.05490196, 0.16862746, 0.40784314, 0.73333335, 0.99607843, 0.99607843, 0.04705882, 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.01960784, 0.6862745 , 0.99607843, 0.99607843, 0.2901961 , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.39215687, 0.99607843, 0.99607843, 0.04705882, 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.63529414, 0.99607843, 0.99607843, 0.2901961 , 0.        , 0.        , 0.        , 0.        , 0.        , 0.14509805, 0.87058824, 0.99607843, 0.8235294 , 0.02745098, 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.63529414, 0.99607843, 0.99607843, 0.2901961 , 0.        , 0.        , 0.        , 0.13333334, 0.41960785, 0.87058824, 0.99607843, 1.        , 0.11764706, 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.02352941, 0.19607843, 0.        , 0.        , 0.63529414, 0.99607843, 0.99607843, 0.9490196 , 0.92941177, 0.92941177, 0.92941177, 0.9529412 , 0.99607843, 0.99607843, 0.99607843, 0.8156863 , 0.03921569, 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.02745098, 0.23529412, 0.        , 0.        , 0.10196079, 0.8392157 , 0.99607843, 0.99607843, 0.99607843, 0.99607843, 0.99607843, 0.99607843, 0.99607843, 0.6       , 0.34509805, 0.02745098, 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.09803922, 0.6039216 , 0.99607843, 0.99607843, 0.8666667 , 0.50980395, 0.50980395, 0.34509805, 0.00392157, 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        , 0.        ]], dtype=float32)>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_raw[0], X_test_normalized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b17db423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_raw[0], y_train_one_hot_encoded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6ae6adc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_raw[0], y_test_one_hot_encoded[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2791fab6",
   "metadata": {},
   "source": [
    "# Expand dimensions of example data to be used by convolutional network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b4903288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4, 3, 4)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.tensorflow.org/api_docs/python/tf/expand_dims\n",
    "\n",
    "X_train_expand_dims = tf.expand_dims(X_train_normalized, axis=-1)\n",
    "\n",
    "X_test_expand_dims = tf.expand_dims(X_test_normalized, axis=-1)\n",
    "\n",
    "X_train_normalized.ndim, X_train_expand_dims.ndim, X_test_normalized.ndim, X_test_expand_dims.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428ae6f0",
   "metadata": {},
   "source": [
    "# Accept the data for use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0fa40a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_expand_dims\n",
    "y_train = y_train_one_hot_encoded\n",
    "\n",
    "X_test = X_test_expand_dims\n",
    "y_test = y_test_one_hot_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cad60b7",
   "metadata": {},
   "source": [
    "# Create the model architechture and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8da64cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 93s 49ms/step - loss: 0.1409 - accuracy: 0.9564 - val_loss: 0.0420 - val_accuracy: 0.9876 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 100s 53ms/step - loss: 0.0477 - accuracy: 0.9859 - val_loss: 0.0306 - val_accuracy: 0.9913 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 104s 56ms/step - loss: 0.0342 - accuracy: 0.9899 - val_loss: 0.0540 - val_accuracy: 0.9846 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 104s 56ms/step - loss: 0.0291 - accuracy: 0.9911 - val_loss: 0.0328 - val_accuracy: 0.9901 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 103s 55ms/step - loss: 0.0227 - accuracy: 0.9934 - val_loss: 0.0296 - val_accuracy: 0.9915 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 105s 56ms/step - loss: 0.0187 - accuracy: 0.9942 - val_loss: 0.0303 - val_accuracy: 0.9920 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 108s 57ms/step - loss: 0.0171 - accuracy: 0.9952 - val_loss: 0.0297 - val_accuracy: 0.9939 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 111s 59ms/step - loss: 0.0150 - accuracy: 0.9955 - val_loss: 0.0256 - val_accuracy: 0.9936 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 105s 56ms/step - loss: 0.0134 - accuracy: 0.9960 - val_loss: 0.0259 - val_accuracy: 0.9926 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 104s 55ms/step - loss: 0.0119 - accuracy: 0.9964 - val_loss: 0.0254 - val_accuracy: 0.9940 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 108s 58ms/step - loss: 0.0115 - accuracy: 0.9970 - val_loss: 0.0340 - val_accuracy: 0.9923 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 109s 58ms/step - loss: 0.0115 - accuracy: 0.9969 - val_loss: 0.0220 - val_accuracy: 0.9945 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 114s 61ms/step - loss: 0.0088 - accuracy: 0.9974 - val_loss: 0.0403 - val_accuracy: 0.9922 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 111s 59ms/step - loss: 0.0086 - accuracy: 0.9976 - val_loss: 0.0426 - val_accuracy: 0.9912 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 112s 60ms/step - loss: 0.0089 - accuracy: 0.9977 - val_loss: 0.0431 - val_accuracy: 0.9904 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 112s 60ms/step - loss: 0.0080 - accuracy: 0.9979 - val_loss: 0.0405 - val_accuracy: 0.9936 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 113s 60ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.0476 - val_accuracy: 0.9922 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc64e58e400>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(RANDOM_SEED_FOR_REPRODUCIBILITY)\n",
    "\n",
    "model_001 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(100, (3, 3), padding=\"same\", activation=tf.keras.activations.relu),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(100, (3, 3), padding=\"same\", activation=tf.keras.activations.relu),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(100, (3, 3), padding=\"same\", activation=tf.keras.activations.relu),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    \n",
    "    tf.keras.layers.Dense(100, activation=tf.keras.activations.relu),\n",
    "    tf.keras.layers.Dense(100, activation=tf.keras.activations.relu),\n",
    "    tf.keras.layers.Dense(100, activation=tf.keras.activations.relu),\n",
    "    \n",
    "    tf.keras.layers.Dense(10, activation=tf.keras.activations.softmax)\n",
    "])\n",
    "\n",
    "model_001.compile(\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[ \"accuracy\" ]\n",
    ")\n",
    "\n",
    "def learning_rate_schedule(epoch, current_learning_rate):\n",
    "    return current_learning_rate\n",
    "\n",
    "model_001.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.LearningRateScheduler(learning_rate_schedule),\n",
    "        tf.keras.callbacks.EarlyStopping('val_accuracy', patience=5, restore_best_weights=True)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f5897b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 8ms/step - loss: 0.0220 - accuracy: 0.9945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.022048039361834526, 0.9944999814033508]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_001.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3e2a99",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "- I was able to introduce callbacks for early stopping. It also restored the weights from the best epoch run after stopping\n",
    "- I introduced a callback for learning rate but did not adjust it this time\n",
    "- I saught a library method for normalizing the example data, but did not find one that would do it simply without reshaping the data. I stuck to dividing by the max for now.\n",
    "- I'm starting to get more of a rythm with this dataset\n",
    "- I was able to successfully get the accuracy over 99%, with 99.76% on the train data and 99.45% on the test data. I didn't create a validation set in this round since the test data is"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
